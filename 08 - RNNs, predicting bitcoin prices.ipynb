{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs, GRUs, and LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Recurrent_neural_network_unfold.png)\n",
    "\n",
    "RNN equations:\n",
    "\n",
    "$h_t = tanh(Vh_{t-1} + Ux_t + b_h)$\n",
    "\n",
    "$o_t = sigmoid(Wh_t + b_o)$\n",
    "\n",
    "![title](Recurrent_Unit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRUs\n",
    "https://en.wikipedia.org/wiki/Gated_recurrent_unit\n",
    "\n",
    "\n",
    "$\\begin{aligned}z_{t}&=sigmoid(W_{z}x_{t}+U_{z}h_{t-1}+b_{z})\\\\r_{t}&=sigmoid(W_{r}x_{t}+U_{r}h_{t-1}+b_{r})\\\\h_{t}&=(1-z_{t})\\circ h_{t-1}+z_{t}\\circ tanh(W_{h}x_{t}+U_{h}(r_{t}\\circ h_{t-1})+b_{h})\\end{aligned}$\n",
    "\n",
    "![title](Gated_Recurrent_Unit,_base_type.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMs\n",
    "\n",
    "https://en.wikipedia.org/wiki/Long_short-term_memory\n",
    "\n",
    "${\\begin{aligned}f_{t}&=sigmoid(W_{f}x_{t}+U_{f}h_{t-1}+b_{f})\\\\i_{t}&=sigmoid(W_{i}x_{t}+U_{i}h_{t-1}+b_{i})\\\\o_{t}&=sigmoid(W_{o}x_{t}+U_{o}h_{t-1}+b_{o})\\\\c_{t}&=f_{t}\\circ c_{t-1}+i_{t}\\circ tanh(W_{c}x_{t}+U_{c}h_{t-1}+b_{c})\\\\h_{t}&=o_{t}\\circ c_{t}\\end{aligned}}$\n",
    "\n",
    "![title](The_LSTM_cell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting bitcoin prices from data of the [bitstamp](https://www.bitstamp.net/) exchange\n",
    "The dataset has very good, 1 minute resolution. We're going to predict the daily price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bitstampUSD_1-min_data_2012-01-01_to_2019-03-13_tail.csv', parse_dates=True,\n",
    "                 date_parser=lambda x: datetime.datetime.fromtimestamp(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we won't fill NA-s here as we take the mean for each day\n",
    "# df = df[['Timestamp', 'Open', 'High', 'Low', 'Close']].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['Timestamp'],unit='s').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute daily price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by date\n",
    "grouped_by_date = df.groupby('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean price on each day\n",
    "df = grouped_by_date.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any missing values?\n",
    "df.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at closing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Close'].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data for LSTM\n",
    "We're going to predict the closing prices one timestep into the future.\n",
    "For this, first we extract the closing prices, then we concatenate it with itself shifted one timestep into the future. These will be the training and test examples.\n",
    "Then we're going to scale the elements of the time series to lie into the interval (-1, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = df.loc[:, 'Close']\n",
    "close.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.concat((close, close.shift(-1)), axis=1)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the trailing NaN\n",
    "examples = examples[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.iloc[:5, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't shuffle the data to preserve the time order\n",
    "num_train = int(examples.shape[0]*0.9)\n",
    "print(\"Number of training examples: {}\".format(num_train))\n",
    "train = examples[:num_train].values\n",
    "test = examples[num_train:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# it is important to fit the scaler only on the training examples so we don't get information about the test examples\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:, 0], train[:, 1]\n",
    "X_test, y_test = test[:, 0], test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5], y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(16, batch_input_shape=[batch_size, 1, 1], stateful=True),\n",
    "    tf.keras.layers.Dense(1) # we don't have an activation here as we're doing regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the batch_size has to divide into the number of examples\n",
    "num_batches = X_train.shape[0] // batch_size\n",
    "X_train = X_train[:num_batches*batch_size]\n",
    "y_train = y_train[:num_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important: shuffle=False as the data points are in time order\n",
    "# important: reset the states between epochs, as the time series restarts from the beginning\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.fit(X_train, y_train, epochs=1, shuffle=False)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape((X_test.shape[0], 1, 1))\n",
    "num_batches = X_test.shape[0] // batch_size\n",
    "X_test = X_test[:num_batches*batch_size]\n",
    "y_test = y_test[:num_batches*batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).squeeze()\n",
    "results = pd.DataFrame(scaler.inverse_transform(np.array([y_test.squeeze(), predictions]).T), columns = ['ground truth', 'prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.diff(1).plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].scatter(results.iloc[:, 0], results.iloc[:, 1])\n",
    "ax[0].set_title('ground truth vs predictions')\n",
    "ax[0].set_xlabel('ground truth')\n",
    "ax[0].set_ylabel('predictions')\n",
    "ax[1].scatter(results.iloc[:, 0].shift(1), results.iloc[:, 1])\n",
    "ax[1].set_title('ground truth vs shifted predictions')\n",
    "ax[1].set_xlabel('ground truth')\n",
    "ax[1].set_ylabel('shifted predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
