{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mark Cuban](https://www.cnbc.com/2019/03/18/billionaire-shark-tank-judge-mark-cuban-if-i-were-to-start-a-business-today-heres-what-it-would-be.html)\n",
    "\n",
    " “As big as PCs were an impact, as big as the internet was, AI is just going to dwarf it. And if you don’t understand it, you’re going to fall behind. Particularly if you run a business.”\n",
    "\n",
    "“I mean, I get it on Amazon and Microsoft and Google, and I run their tutorials. If you go in my bathroom, there’s a book, ‘Machine Learning for Idiots.’ Whenever I get a break, I’m reading it”\n",
    "\n",
    "“If you don’t know how to use it and you don’t understand it and you can’t at least at have a basic understanding of the different approaches and how the algorithms work, you can be blindsided in ways you couldn’t even possibly imagine.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some applications of ML\n",
    "\n",
    "1. Hedge funds use satellite data of parking lots to predict growth of companies\n",
    "2. Using geolocation data to predict footfall of shopping malls\n",
    "3. Banking: analyze customer spending patterns and preemptively propose loan\n",
    "4. Proposing travel insurance as soon as you buy a plane ticket\n",
    "5. Analyzing credit risk\n",
    "6. [vPhrase](https://www.vphrase.com/): generating natural language from portfolio data for investors to summarize the portfolio; personalized reports for branch managers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install Anaconda from https://anaconda.org/\n",
    "2. Create a new environment with the required packages: ```conda create -n summer_school ipython jupyter matplotlib pandas scikit-learn tensorflow nltk```\n",
    "3. To activate it: ```conda activate summer_school```\n",
    "4. To deactivate: ```conda deactivate```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this only the first time and download \"book\"\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebook basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a markdown cell, the next ones are code cells\n",
    "- The notebook is running a kernel (here, Python), the code cells are executed by this kernel\n",
    "- Very useful to do any command or check shortcuts: p\n",
    "- Move around: arrow keys or j, k\n",
    "- Run a cell and go to next cell: Shift+Enter\n",
    "- Go to edit mode to edit a cell: click or Enter\n",
    "- Get help about while editing: Shift-Tab, press twice to get more help\n",
    "- Back to command mode from edit mode: Esc\n",
    "- New cell above: a\n",
    "- New cell below: b\n",
    "- Delete cell: x\n",
    "- Run a cell and insert new cell below: Alt-Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a simple neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a code cell that contains Python code\n",
    "# we usually start with the imports\n",
    "# these are the imports we usually use for machine learning\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset URL: https://www.kaggle.com/neiljs/all-shark-tank-us-pitches-deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sharktankpitchesdeals.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pitch in df.loc[:3, 'Pitched_Business_Desc']:\n",
    "    print(pitch)\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [pitch for pitch in df.loc[:, 'Pitched_Business_Desc']]\n",
    "corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [deal for deal in df.loc[:, 'Deal_Status']]\n",
    "targets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=20)\n",
    "bows = count_vectorizer.fit_transform(corpus)\n",
    "pd.DataFrame(bows.toarray(), columns=count_vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=num_of_features)\n",
    "bows = count_vectorizer.fit_transform(corpus)\n",
    "print(\"We have {} pitches.\".format(bows.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the problem: we have sparse arrays, but neural network need dense arrays!\n",
    "# the solution will be word embeddings, here we just convert to dense arrays\n",
    "bows = bows.toarray().astype(np.float32)\n",
    "targets = np.array(targets, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train = 600\n",
    "X_train, y_train = bows[:num_of_train], targets[:num_of_train]\n",
    "X_test, y_test = bows[num_of_train:], targets[num_of_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights of a single neuron are in a vector\n",
    "\n",
    "![title](nn_vector.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1, 2, 3])\n",
    "x = np.array([1, 2, 3])\n",
    "w @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights of a layer of neurons are in a matrix\n",
    "![title](nn_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([[1, 2, 3], [1, 1, 1], [2, 2, 2]])\n",
    "x = np.array([1, 2, 3])\n",
    "w @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [3, 4, 5]\n",
    "w @ x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(w @ sigmoid(w @ x + b) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-7, 7, 0.01)\n",
    "fix, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "ax.plot(x, sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relu activation function\n",
    "x = np.arange(-7, 7, 0.01)\n",
    "fix, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "ax.plot(x, [max(xe, 0) for xe in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization algorithm: some kind of gradient descent\n",
    "\n",
    "![title](Gradient_descent.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: binary crossentropy\n",
    "\n",
    "If $y_i$ are the true labels, and $\\hat{y}_i$ are the predictions of the network:\n",
    "\n",
    "$- \\frac{1}{N} \\sum_{i=1}^{N} y_i * log(\\hat{y}_i) + (1-y_i)*log(1-\\hat{y}_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.001, 1.2, 0.01)\n",
    "fix, ax = plt.subplots(1, 1, figsize=(20, 10))\n",
    "ax.plot(x, -np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational graph\n",
    "![title](tensors_flowing.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compile our neural network model\n",
    "# we also have to choose an optimizer and a loss function\n",
    "# for a binary classification task usually binary cross-entropy is fine\n",
    "# we use accuracy as the metric\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training or in other words, fitting the model to the data\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks very good, but\n",
    "# evaluating on the test set\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with another dataset!\n",
    "Movie reviews - positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_reviews.raw('neg/cv000_29416.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, targets = zip(*[(movie_reviews.raw(fileid), category)\n",
    "                         for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=num_of_features)\n",
    "bows = count_vectorizer.fit_transform(corpus)\n",
    "print(\"We have {} documents.\".format(bows.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert targets to numbers\n",
    "targets = np.array([0 if target == 'neg' else 1 for target in targets])\n",
    "targets[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to shuffle\n",
    "perm = np.random.permutation(len(targets))\n",
    "bows = bows[perm]\n",
    "targets = targets[perm].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bows = bows.toarray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_train = 1800\n",
    "X_train, y_train = bows[:num_of_train], targets[:num_of_train]\n",
    "X_test, y_test = bows[num_of_train:], targets[num_of_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
